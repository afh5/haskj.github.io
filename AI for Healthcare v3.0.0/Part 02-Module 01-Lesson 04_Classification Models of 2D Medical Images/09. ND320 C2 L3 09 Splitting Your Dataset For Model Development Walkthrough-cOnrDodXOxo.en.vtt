WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.045
Given a dataset to use in algorithm development,

00:00:03.045 --> 00:00:06.600
it's critical that you understand how much data to use when training

00:00:06.600 --> 00:00:10.950
your algorithm and how much to leave held out for post-training validation.

00:00:10.950 --> 00:00:13.680
It's also very important to curate your training

00:00:13.680 --> 00:00:16.350
and validation data in a way that is appropriate to

00:00:16.350 --> 00:00:18.780
your clinical application as this will have

00:00:18.780 --> 00:00:22.830
a direct effect on how the algorithm is cleared to be used clinically.

00:00:22.830 --> 00:00:26.110
In the world of medical imaging algorithm development,

00:00:26.110 --> 00:00:28.650
you'll often be given a dataset that looks like

00:00:28.650 --> 00:00:33.205
this and you'll need to turn it into something that looks more like this.

00:00:33.205 --> 00:00:37.280
We did a bit of this in lesson 2 and we talked about how to extract

00:00:37.280 --> 00:00:41.240
metadata about a dataset from the DICOM header and other sources.

00:00:41.240 --> 00:00:45.980
But there are some steps we need to take after that to prepare us for deep learning.

00:00:45.980 --> 00:00:49.310
Before feeding your data into a deep learning model,

00:00:49.310 --> 00:00:51.590
you'll need to split it into two sets.

00:00:51.590 --> 00:00:56.030
A training set, which is data that your deep learning algorithm will use to

00:00:56.030 --> 00:01:01.295
learn the features that differentiate between your classes and a validation set.

00:01:01.295 --> 00:01:04.580
Your algorithm will never use this set for learning.

00:01:04.580 --> 00:01:07.490
This is the set that you will use to determine if

00:01:07.490 --> 00:01:11.605
your algorithm is actually learning to discriminate between your classes.

00:01:11.605 --> 00:01:16.025
We want to maximize the data that our algorithm sees to learn features,

00:01:16.025 --> 00:01:18.935
while also leaving enough validation held out

00:01:18.935 --> 00:01:22.550
so that we can confidently determine the algorithm's performance.

00:01:22.550 --> 00:01:26.725
The general rule of thumb is to split your data 80, 20.

00:01:26.725 --> 00:01:31.280
The data should be split to maximize for prevalence of positive cases.

00:01:31.280 --> 00:01:35.060
In other words, make sure that 80 per cent of your positive cases end

00:01:35.060 --> 00:01:39.200
up in the training set and 20 per cent end up in the validation set.

00:01:39.200 --> 00:01:44.765
Note that an image should never be used for both training and validation.

00:01:44.765 --> 00:01:49.235
The properties of your training and validation set also differ.

00:01:49.235 --> 00:01:51.065
When we train an algorithm,

00:01:51.065 --> 00:01:53.870
we want the model architecture to see equal numbers of

00:01:53.870 --> 00:01:57.850
cases that belong to each class that we're teaching it to distinguish between.

00:01:57.850 --> 00:02:01.520
Even if one class is really rare in the wild,

00:02:01.520 --> 00:02:04.220
we want the model to be able to recognize that just

00:02:04.220 --> 00:02:07.330
as well as I can recognize the common classes.

00:02:07.330 --> 00:02:09.860
For all other variables in your dataset,

00:02:09.860 --> 00:02:11.120
such as age, sex,

00:02:11.120 --> 00:02:13.400
and race, your training set should follow

00:02:13.400 --> 00:02:16.640
the same distribution as your original file dataset.

00:02:16.640 --> 00:02:22.460
So if your original dataset contained individuals banding from ages 10 to 80,

00:02:22.460 --> 00:02:25.660
your training search should also have this full age range.

00:02:25.660 --> 00:02:29.240
Usually however, classification tasks that we are presented

00:02:29.240 --> 00:02:32.870
with in the real world do not offer balanced classes.

00:02:32.870 --> 00:02:35.510
For example, if you're creating an algorithm to

00:02:35.510 --> 00:02:38.545
classify the presence or absence of a rare disease,

00:02:38.545 --> 00:02:42.205
most of your real-world scans will be negative cases.

00:02:42.205 --> 00:02:44.780
To this end, when we validate our model,

00:02:44.780 --> 00:02:49.075
we want our model to see a class imbalance that reflects the real-world.

00:02:49.075 --> 00:02:51.755
More on the statistics behind this later.

00:02:51.755 --> 00:02:53.360
Same with the training set,

00:02:53.360 --> 00:02:55.580
make sure that all of your other variables are

00:02:55.580 --> 00:02:59.425
distributed the same way that they were in the original dataset.

00:02:59.425 --> 00:03:03.095
Let's go through an example together of splitting a dataset.

00:03:03.095 --> 00:03:07.145
Here, we have a dataset that has 100 samples in it,

00:03:07.145 --> 00:03:10.210
30 of which are positive, shown in green.

00:03:10.210 --> 00:03:13.190
The first step would be to split our data 80,

00:03:13.190 --> 00:03:16.460
20 using the positive class as the feature to split on.

00:03:16.460 --> 00:03:19.160
In other words, we want to make sure 80 per cent of

00:03:19.160 --> 00:03:23.885
the positive cases are in the training set and 20 per cent in the validation.

00:03:23.885 --> 00:03:26.660
Here we end up with 24 positive cases in

00:03:26.660 --> 00:03:30.335
our training set and six positive cases in our validation.

00:03:30.335 --> 00:03:34.820
See here that our training set though is not balanced for positive and negative.

00:03:34.820 --> 00:03:38.255
So our model will see way more negative classes when learning,

00:03:38.255 --> 00:03:39.820
which is not what we want.

00:03:39.820 --> 00:03:42.260
The next step then would be to discard

00:03:42.260 --> 00:03:45.830
negative training cases so that our training set is balanced.

00:03:45.830 --> 00:03:49.010
When you do this, make sure that your negative cases are still

00:03:49.010 --> 00:03:53.845
distributed across the population and randomization can help with this.

00:03:53.845 --> 00:03:57.080
Keras provides a really great tool for

00:03:57.080 --> 00:04:00.065
doing this training and validation split automatically.

00:04:00.065 --> 00:04:03.580
They've developed a package called train test split.

00:04:03.580 --> 00:04:06.845
It allows you to split with a certain percentage.

00:04:06.845 --> 00:04:10.270
So here, 20 per cent going into our validation set.

00:04:10.270 --> 00:04:12.500
It also allows you to choose

00:04:12.500 --> 00:04:15.380
what class you're splitting on so that you know you're getting

00:04:15.380 --> 00:04:21.020
20 percent of positive cases in your validation set and 80 per cent in the training set,

00:04:21.020 --> 00:04:26.220
not just splitting the data into two random 80, 20 chunks.

