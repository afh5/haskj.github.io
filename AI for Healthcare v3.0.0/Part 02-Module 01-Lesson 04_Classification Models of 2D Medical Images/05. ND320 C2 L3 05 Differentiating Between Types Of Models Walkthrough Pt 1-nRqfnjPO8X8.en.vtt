WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.810
I know that everyone is eager to get to the deep learning.

00:00:03.810 --> 00:00:05.640
But before we get there,

00:00:05.640 --> 00:00:10.275
let's try to understand why deep learning and where this field originated.

00:00:10.275 --> 00:00:14.115
We'll go back to the old days first of classic machine learning.

00:00:14.115 --> 00:00:16.380
Remember from lesson one how we have

00:00:16.380 --> 00:00:20.450
three main types of imaging algorithms for 2D medical images?

00:00:20.450 --> 00:00:24.030
There's segmentation, which helps us define outlines around

00:00:24.030 --> 00:00:28.755
specific findings in an image and measure their size, there's localization,

00:00:28.755 --> 00:00:31.080
which identifies the region of an image with

00:00:31.080 --> 00:00:34.440
a certain finding and draws a bounding box around it,

00:00:34.440 --> 00:00:36.695
and finally, there's classification,

00:00:36.695 --> 00:00:40.790
which tells us if something is or is not present in an image.

00:00:40.790 --> 00:00:44.290
This actually hasn't changed much with the advent of deep learning,

00:00:44.290 --> 00:00:47.765
and these are still the main three areas of algorithm types.

00:00:47.765 --> 00:00:50.240
The biggest difference between machine learning and

00:00:50.240 --> 00:00:53.575
deep learning is the concept of feature selection.

00:00:53.575 --> 00:00:55.775
Before deep learning existed,

00:00:55.775 --> 00:00:58.580
algorithm developers had to work very hard to

00:00:58.580 --> 00:01:02.920
predefine features in an image that were important for their task.

00:01:02.920 --> 00:01:06.184
These features could come in a multitude of flavors,

00:01:06.184 --> 00:01:08.810
but it is really considered an art as to how

00:01:08.810 --> 00:01:11.920
they are crafted and refined for specific tasks,

00:01:11.920 --> 00:01:14.875
and it takes a lot of time and effort.

00:01:14.875 --> 00:01:20.015
An example of a feature might be the intensity gradient between adjacent pixels,

00:01:20.015 --> 00:01:23.630
which is steeper when there is a tumor versus healthy tissue.

00:01:23.630 --> 00:01:25.880
When deep learning came along,

00:01:25.880 --> 00:01:30.410
it was groundbreaking because it worked to discover important features,

00:01:30.410 --> 00:01:34.255
taking this burden off of the algorithm researchers.

00:01:34.255 --> 00:01:38.045
Before deep learning, algorithm developers had to spend

00:01:38.045 --> 00:01:42.185
a long time looking at their images and understanding their properties.

00:01:42.185 --> 00:01:44.840
During this process, developers would often need

00:01:44.840 --> 00:01:48.080
input from disease experts and radiologists about

00:01:48.080 --> 00:01:51.350
what particular features of an image they would look at to make

00:01:51.350 --> 00:01:55.825
their diagnoses and then translate these into features for machine learning.

00:01:55.825 --> 00:01:57.860
Once features are defined,

00:01:57.860 --> 00:02:00.335
they're given to an algorithm, for example,

00:02:00.335 --> 00:02:04.024
a logistic regression or support vector machine algorithm,

00:02:04.024 --> 00:02:09.220
to learn how these specific features differentiate between classes of images.

00:02:09.220 --> 00:02:12.500
In the end, the algorithm returns an output based

00:02:12.500 --> 00:02:15.770
on the separability of the features that it was exposed to.

00:02:15.770 --> 00:02:20.780
Note that lots of these algorithms are really powerful and highly accurate,

00:02:20.780 --> 00:02:23.420
and there are still many use cases out there for

00:02:23.420 --> 00:02:26.765
which classic machine learning is sufficient and reliable.

00:02:26.765 --> 00:02:29.540
With deep learning, the algorithm developer

00:02:29.540 --> 00:02:32.530
doesn't need to start with the feature selection process.

00:02:32.530 --> 00:02:36.320
They instead start first with the algorithms architecture.

00:02:36.320 --> 00:02:38.210
We'll dive more into this later,

00:02:38.210 --> 00:02:42.005
but you've probably had some experience with the CNN architecture,

00:02:42.005 --> 00:02:45.710
which is most commonly used for classification of images.

00:02:45.710 --> 00:02:50.780
What the human eye can detect and then integrate into the brain about images,

00:02:50.780 --> 00:02:53.390
is not always something that can be translated into

00:02:53.390 --> 00:02:57.055
a simple feature such as tumors appear brighter.

00:02:57.055 --> 00:03:01.445
Oftentimes, radiologists are seemingly able to just intuit

00:03:01.445 --> 00:03:03.695
the appropriate diagnosis in the image

00:03:03.695 --> 00:03:06.830
because they have seen tens of thousands of images,

00:03:06.830 --> 00:03:11.170
and defining a set of features that they're looking for is not the full story.

00:03:11.170 --> 00:03:13.175
When deep learning came along,

00:03:13.175 --> 00:03:15.410
it started to solve this problem for us.

00:03:15.410 --> 00:03:18.830
Deep learning algorithms discover features in a way

00:03:18.830 --> 00:03:23.060
similar to how a human would discover features by looking at many,

00:03:23.060 --> 00:03:27.605
many images and learning what makes certain images different from each other.

00:03:27.605 --> 00:03:32.270
This technique proved to be superior to handcrafted features for machine learning,

00:03:32.270 --> 00:03:33.905
for both cats and dogs,

00:03:33.905 --> 00:03:36.410
and x-rays and mammograms.

00:03:36.410 --> 00:03:39.405
Finally, like classic machine learning,

00:03:39.405 --> 00:03:41.915
our deep learning algorithm returns an output

00:03:41.915 --> 00:03:45.335
indicating whether or not a finding is present in an image.

00:03:45.335 --> 00:03:49.340
The performance of deep learning shows to be most powerful when

00:03:49.340 --> 00:03:53.195
we start having to deal with images in which differences are very subtle,

00:03:53.195 --> 00:03:56.520
which is often the case in medical imaging.

