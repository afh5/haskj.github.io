WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.320
To get a more accurate idea of the performance after optimizing hyperparameter,

00:00:04.320 --> 00:00:07.890
we need to use a technique called nested cross-validation.

00:00:07.890 --> 00:00:13.170
In this technique, we pick the best set of hyperparameters on a subset of the data,

00:00:13.170 --> 00:00:15.410
and then evaluate it on the holdout set.

00:00:15.410 --> 00:00:19.680
This is similar to using a train validation tests set split,

00:00:19.680 --> 00:00:23.055
but we don't have enough data to split our data set into three parts.

00:00:23.055 --> 00:00:28.275
So we can nest the hyperparameter selection into another layer of cross-validation.

00:00:28.275 --> 00:00:29.880
So this is how it works.

00:00:29.880 --> 00:00:35.460
In nested cross-validation, we have two cross-validation folds going on.

00:00:35.460 --> 00:00:39.675
We'll store the confusion matrix for the outer cross-validation here,

00:00:39.675 --> 00:00:44.530
and the outer loop we'll split the dataset into a test set,

00:00:44.530 --> 00:00:47.425
and then a training plus validation set.

00:00:47.425 --> 00:00:53.000
We'll keep track of the best hyperparameters for this training and validation set.

00:00:53.000 --> 00:00:59.590
On that set, we will iterates through our selection of hyperparameters.

00:00:59.590 --> 00:01:02.000
Just like we did above, we will build

00:01:02.000 --> 00:01:04.760
a new model for each set of hyperparameters and then

00:01:04.760 --> 00:01:10.205
compute to leave one subject out performance for that set of hyperparameters.

00:01:10.205 --> 00:01:13.580
Here, instead of testing on the test set,

00:01:13.580 --> 00:01:16.070
we're testing on our validation set and we compute

00:01:16.070 --> 00:01:19.310
the classification accuracy on the validation set.

00:01:19.310 --> 00:01:22.490
Because we're keeping track of our best set of hyperparameters,

00:01:22.490 --> 00:01:26.770
we can now build the best model for this training and validation sets.

00:01:26.770 --> 00:01:30.150
In this time, our model has not seen the test set.

00:01:30.150 --> 00:01:32.720
So when we test our model on the test set,

00:01:32.720 --> 00:01:37.315
we can be sure that we're not overfitting either the parameters or the hyperparameters.

00:01:37.315 --> 00:01:40.295
We then compute the confusion matrix on the test set

00:01:40.295 --> 00:01:43.540
and aggregate it for all the outer cross-validation folds.

00:01:43.540 --> 00:01:45.410
This code takes a long time to run,

00:01:45.410 --> 00:01:48.095
so I've already run it before this video.

00:01:48.095 --> 00:01:53.540
When we compute the classification accuracy by nest cross-validation,

00:01:53.540 --> 00:01:58.685
we can see a significant drop in our classifier's performance.

00:01:58.685 --> 00:02:03.720
In the next video, we'll take a look at another hyperparameter that can be optimized.

