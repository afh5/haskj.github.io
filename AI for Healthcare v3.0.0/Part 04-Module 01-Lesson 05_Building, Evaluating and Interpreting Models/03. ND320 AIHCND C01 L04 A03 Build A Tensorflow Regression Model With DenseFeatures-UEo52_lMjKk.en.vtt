WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.970
Now that you have learned about DenseFeatures,

00:00:02.970 --> 00:00:06.240
let's use it to build a regression model with

00:00:06.240 --> 00:00:10.455
some of the TensorFlow feature call methods you learned earlier.

00:00:10.455 --> 00:00:12.480
For this walk through,

00:00:12.480 --> 00:00:19.185
we use the same car mileage data set that the TensorFlow regression tutorial uses.

00:00:19.185 --> 00:00:22.590
Largely use the same pr-processing and modeling code,

00:00:22.590 --> 00:00:24.780
except that we will use

00:00:24.780 --> 00:00:29.625
DenseFeatures in a TensorFlow feature column for feature engineering.

00:00:29.625 --> 00:00:32.040
Just to set expectations right,

00:00:32.040 --> 00:00:35.980
we've largely use the TensorFlow regression tutorial.

00:00:35.980 --> 00:00:38.255
This is just to illustrate,

00:00:38.255 --> 00:00:39.770
as I just mentioned,

00:00:39.770 --> 00:00:44.035
how to preprocess the data with the methods we just went over.

00:00:44.035 --> 00:00:49.440
It is not an optimized model and you will have opportunity and challenge to improve it.

00:00:49.440 --> 00:00:52.475
So getting back to the preprocessing code,

00:00:52.475 --> 00:00:56.690
I put the code here in a notebook for the preprocessing from the tutorial.

00:00:56.690 --> 00:00:59.675
It's largely the same as the tutorial.

00:00:59.675 --> 00:01:03.755
Just to note that the output is a normalized dataset,

00:01:03.755 --> 00:01:06.535
so they've normalized in numerical features.

00:01:06.535 --> 00:01:09.355
We'll load those up and use those for the walk through.

00:01:09.355 --> 00:01:14.630
So we will load the normalized train and test datasets here.

00:01:14.630 --> 00:01:18.440
Then use the same ETL method we learned earlier,

00:01:18.440 --> 00:01:23.890
where we load them into Pandas DataFrames and convert them to TensorFlow datasets.

00:01:23.890 --> 00:01:26.390
Then take a sample to verify,

00:01:26.390 --> 00:01:30.685
which we'll look at later when we use the TensorFlow feature column API.

00:01:30.685 --> 00:01:35.885
Next, we will convert the one categorical feature origin,

00:01:35.885 --> 00:01:38.840
which is the country of origin for the vehicle

00:01:38.840 --> 00:01:42.515
and create a vocab from just a list of unique values,

00:01:42.515 --> 00:01:45.130
since the unique values are small.

00:01:45.130 --> 00:01:47.720
So you can see the unique values are here,

00:01:47.720 --> 00:01:50.270
and we're just passing this into this function.

00:01:50.270 --> 00:01:53.450
Then we use the indicator function again that we

00:01:53.450 --> 00:01:56.935
learned about earlier to create a one_hot_encoded_feature.

00:01:56.935 --> 00:01:59.430
As you can see, here is the output of

00:01:59.430 --> 00:02:03.515
that one_hot_encoded_feature on the sample we created earlier.

00:02:03.515 --> 00:02:05.420
Then we can build

00:02:05.420 --> 00:02:10.820
the TensorFlow numerical features using the method we learned earlier as well.

00:02:10.820 --> 00:02:12.859
In this case, however,

00:02:12.859 --> 00:02:15.350
our data has already been normalized for us,

00:02:15.350 --> 00:02:18.335
so we don't need to add a normalizer function.

00:02:18.335 --> 00:02:23.105
So if we take a look, this is a numeric column function that we learned about earlier.

00:02:23.105 --> 00:02:28.190
In this case, we don't see the normalizer function as an argument as we mentioned.

00:02:28.190 --> 00:02:30.740
In this loop, it's just looping through

00:02:30.740 --> 00:02:33.500
all the different numeric columns and then

00:02:33.500 --> 00:02:36.800
creating a TensorFlow numeric feature for each one of them,

00:02:36.800 --> 00:02:38.450
and then creating that list.

00:02:38.450 --> 00:02:41.665
So here's a list of every numeric column.

00:02:41.665 --> 00:02:46.325
Now we've converted to a TensorFlow numeric column feature.

00:02:46.325 --> 00:02:49.010
If we take just the first example,

00:02:49.010 --> 00:02:53.495
cylinders, here's that feature represented in the Tensor.

00:02:53.495 --> 00:02:58.310
Then we can use the dense features function to combine

00:02:58.310 --> 00:03:00.620
the TensorFlow feature columns as

00:03:00.620 --> 00:03:04.630
a feature layer to be added to the sequential API at the model.

00:03:04.630 --> 00:03:08.150
So if we take the TensorFlow features that we just created,

00:03:08.150 --> 00:03:12.530
put them into a list and then pass in into a dense features function,

00:03:12.530 --> 00:03:14.840
we can create a dense feature layer,

00:03:14.840 --> 00:03:19.135
which will pass to the first layer of a sequential API model.

00:03:19.135 --> 00:03:24.310
Hopefully, the TensorFlow Keras model and functions should be familiar to you.

00:03:24.310 --> 00:03:27.385
This is just the architecture from the tutorial again,

00:03:27.385 --> 00:03:30.470
nothing too complicated, this is more just to

00:03:30.470 --> 00:03:34.600
illustrate the preprocessing functions and the end-to-end process.

00:03:34.600 --> 00:03:37.820
So these are just a couple of fully connected layers,

00:03:37.820 --> 00:03:39.350
I'll put to a final layer,

00:03:39.350 --> 00:03:44.035
fully connected layer and using common activation ReLU function.

00:03:44.035 --> 00:03:47.015
Then you can play around with the different optimizers as well.

00:03:47.015 --> 00:03:48.635
Lastly, just to know,

00:03:48.635 --> 00:03:50.810
we went over common regression metrics.

00:03:50.810 --> 00:03:55.640
So MSE, MEA, these should be common metrics that you should be familiar with.

00:03:55.640 --> 00:03:58.030
In this case, we're using MSE.

00:03:58.030 --> 00:04:02.700
Now that we went over how to use dense features to build a regression model,

00:04:02.700 --> 00:04:06.110
we can build a model here and then train it.

00:04:06.110 --> 00:04:09.215
In this case, I'm training over 100 epochs,

00:04:09.215 --> 00:04:14.605
and just having an early stopping if it doesn't improve after 50 epochs.

00:04:14.605 --> 00:04:17.405
Again, this is not an optimized model,

00:04:17.405 --> 00:04:21.110
just larger utilizing what was done in TensorFlow tutorial,

00:04:21.110 --> 00:04:26.545
which was just to illustrate the end-to-end process not to build an optimized model.

00:04:26.545 --> 00:04:30.470
Now you can see the output from this model on the test set here.

00:04:30.470 --> 00:04:32.600
As you can see, not a great performance.

00:04:32.600 --> 00:04:34.340
So definitely feel free to play

00:04:34.340 --> 00:04:38.110
around with the notebook and see how you can improve this model.

00:04:38.110 --> 00:04:39.700
In this walk through,

00:04:39.700 --> 00:04:45.155
we reviewed many of the concepts that we went over using TensorFlow for ETL,

00:04:45.155 --> 00:04:48.280
creating features with the feature column API.

00:04:48.280 --> 00:04:51.020
Now using dense features to combine

00:04:51.020 --> 00:04:54.485
those features into a layer that can feed into your model.

00:04:54.485 --> 00:04:58.770
Hopefully, this makes things easier for you to build models.

