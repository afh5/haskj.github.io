WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.455
In the previous lesson,

00:00:01.455 --> 00:00:06.180
we drilled down into performance statistics like specificity and sensitivity.

00:00:06.180 --> 00:00:10.510
Here's where they become super important for translation into the real world.

00:00:10.510 --> 00:00:15.060
The way our algorithm performs directly ties to its intended use.

00:00:15.060 --> 00:00:21.045
Imagine I had this clinical dataset with five positive cases for cancer,

00:00:21.045 --> 00:00:24.375
and 95 negative cases for cancer.

00:00:24.375 --> 00:00:29.295
Our researcher comes along and tells me that he has an algorithm that looks like this,

00:00:29.295 --> 00:00:33.895
that can distinguish between cancer and no cancer with 95 percent accuracy.

00:00:33.895 --> 00:00:35.735
Sounds pretty good, right?

00:00:35.735 --> 00:00:37.360
Well, not really.

00:00:37.360 --> 00:00:40.350
Because cancer is so rare in my clinical data,

00:00:40.350 --> 00:00:42.450
because my classes are imbalanced.

00:00:42.450 --> 00:00:48.200
In fact, this algorithm is predicting that all 100 cases are negative,

00:00:48.200 --> 00:00:50.960
to achieve that 95 percent accuracy number.

00:00:50.960 --> 00:00:55.505
Because in truth, it correctly predicted 95 percent of the image labels.

00:00:55.505 --> 00:00:56.825
But to be honest,

00:00:56.825 --> 00:00:58.835
this algorithm is useless.

00:00:58.835 --> 00:01:03.905
We touched on this idea of assessing negative cases separately in Lesson 1.

00:01:03.905 --> 00:01:07.040
Recall then that we learned about specificity.

00:01:07.040 --> 00:01:08.990
This measure looks at the number of

00:01:08.990 --> 00:01:12.225
negative cases accurately identified by the algorithm,

00:01:12.225 --> 00:01:16.010
and divides it by all of the negative cases in the dataset,

00:01:16.010 --> 00:01:21.170
giving us the proportion of accurately identified negative cases in the dataset.

00:01:21.170 --> 00:01:26.900
This holds value, but it's not the measure that we most commonly use in clinical tests.

00:01:26.900 --> 00:01:29.705
Because normal cases, in other words,

00:01:29.705 --> 00:01:34.070
negative cases, take the majority of all of the cases we see in the real world.

00:01:34.070 --> 00:01:38.570
So we always have an imbalanced dataset with more negative cases than positive,

00:01:38.570 --> 00:01:40.750
just like in the example we just saw.

00:01:40.750 --> 00:01:44.570
Just like accuracy, specificity would be really high,

00:01:44.570 --> 00:01:47.840
even if the algorithm labels all cases as negative,

00:01:47.840 --> 00:01:51.955
since it measures the proportion of accurately identified negative cases.

00:01:51.955 --> 00:01:53.960
It's not that helpful.

00:01:53.960 --> 00:01:56.690
Another issue with specificity is that it does

00:01:56.690 --> 00:01:59.435
not take true positives into account at all,

00:01:59.435 --> 00:02:03.685
which is what we care about when we are trying to identify the disease.

00:02:03.685 --> 00:02:07.120
We also learned a lot about a measure called sensitivity.

00:02:07.120 --> 00:02:10.805
This is more frequently used as a clinical performance metric.

00:02:10.805 --> 00:02:12.170
Recall from Lesson 1,

00:02:12.170 --> 00:02:16.970
that it is used to calculate the number of positive cases identified by the algorithm,

00:02:16.970 --> 00:02:20.105
divided by all of the positive cases in the dataset.

00:02:20.105 --> 00:02:24.970
This gives us the proportion of accurately identified positive cases in the dataset,

00:02:24.970 --> 00:02:26.785
and as we mentioned in Lesson 1,

00:02:26.785 --> 00:02:31.285
this measure has two other names: the true positive rate and recall.

00:02:31.285 --> 00:02:33.855
Recall is really important, clinically.

00:02:33.855 --> 00:02:35.480
Because in medicine, usually,

00:02:35.480 --> 00:02:38.680
we care much more about finding disease cases,

00:02:38.680 --> 00:02:40.830
in other words, positive cases,

00:02:40.830 --> 00:02:43.100
than we care about finding normal cases,

00:02:43.100 --> 00:02:44.960
in other words, negative cases.

00:02:44.960 --> 00:02:48.910
This metric tells us how often we correctly find a positive case.

00:02:48.910 --> 00:02:53.720
Notice that this metric takes nothing into account about false positives.

00:02:53.720 --> 00:02:56.495
So if the algorithm says the case is positive,

00:02:56.495 --> 00:02:58.820
but it's actually negative, we wouldn't know.

00:02:58.820 --> 00:03:03.100
If our algorithm predicted positive for every image in the dataset,

00:03:03.100 --> 00:03:05.180
we'd find all the disease cases,

00:03:05.180 --> 00:03:08.545
but that would still wouldn't be very useful, would it?

00:03:08.545 --> 00:03:12.005
So specificity ignored true positives,

00:03:12.005 --> 00:03:13.910
and sensitivity, or recall,

00:03:13.910 --> 00:03:16.355
didn't take into account false positives.

00:03:16.355 --> 00:03:19.085
We stated why we would care about both of those metrics,

00:03:19.085 --> 00:03:22.690
which brings us to a third metric, precision.

00:03:22.690 --> 00:03:28.490
Precision looks at the number of positive cases accurately identified by the algorithm,

00:03:28.490 --> 00:03:33.305
divided by all of the cases identified as positive by the algorithm,

00:03:33.305 --> 00:03:36.745
no matter whether they were identified right or wrong.

00:03:36.745 --> 00:03:41.280
You're probably noticing a pattern with all of these statistics having multiple names,

00:03:41.280 --> 00:03:43.580
and it holds true for precision too.

00:03:43.580 --> 00:03:47.980
This metric is commonly referred to as the positive predictive value.

00:03:47.980 --> 00:03:52.520
We're going to focus on precision and recall for assessing performance clinically.

00:03:52.520 --> 00:03:55.730
So let's talk about what these two things are measuring,

00:03:55.730 --> 00:03:57.400
and when and why they're useful.

00:03:57.400 --> 00:04:00.545
As translational scientists, it's our job to think

00:04:00.545 --> 00:04:04.100
outside of the box about just classifying images as yes or no,

00:04:04.100 --> 00:04:07.850
and to truly understand the pain points of radiologists and patients,

00:04:07.850 --> 00:04:09.910
who will be impacted by our tool.

00:04:09.910 --> 00:04:13.035
AI isn't just used for diagnosing diseases,

00:04:13.035 --> 00:04:16.480
sometimes it's best used for clinical workflow prioritization.

00:04:16.480 --> 00:04:19.940
So precision is a great metric to optimize

00:04:19.940 --> 00:04:23.690
for when we care most about confidence in positive results.

00:04:23.690 --> 00:04:26.780
A high precision test gives you more confidence that

00:04:26.780 --> 00:04:30.100
a positive test result is actually positive.

00:04:30.100 --> 00:04:34.090
This metric, however, does not take false negatives into account.

00:04:34.090 --> 00:04:38.480
So a high precision test could still miss a lot of positive cases.

00:04:38.480 --> 00:04:41.000
Because of this, high precision tests don't

00:04:41.000 --> 00:04:44.060
necessarily make for great standalone diagnostics,

00:04:44.060 --> 00:04:48.880
but they're beneficial when you want to confirm a suspected diagnosis.

00:04:48.880 --> 00:04:51.005
Recall, on the other hand,

00:04:51.005 --> 00:04:54.005
allows us to confidently rule out disease.

00:04:54.005 --> 00:04:57.425
When a test with high recall returns a negative result,

00:04:57.425 --> 00:05:01.205
you can be pretty confident that the result is truly negative.

00:05:01.205 --> 00:05:05.120
Recall does not take false positives into account though,

00:05:05.120 --> 00:05:07.370
so you may have a really high recall,

00:05:07.370 --> 00:05:11.260
but you're still labeling a lot of negative cases as positive.

00:05:11.260 --> 00:05:14.030
Because of this, clinical applications for

00:05:14.030 --> 00:05:17.690
high recall tests are good for things like screening studies,

00:05:17.690 --> 00:05:21.320
where you really want to make sure if someone doesn't have a disease,

00:05:21.320 --> 00:05:24.470
or worklist prioritization where you want to make sure that

00:05:24.470 --> 00:05:28.045
people without the disease are being deprioritized.

00:05:28.045 --> 00:05:33.110
Optimizing one of these metrics usually comes at the expense of sacrificing the other.

00:05:33.110 --> 00:05:35.660
So let's learn more about that now,

00:05:35.660 --> 00:05:38.580
and what it looks like in a real-world setting.

